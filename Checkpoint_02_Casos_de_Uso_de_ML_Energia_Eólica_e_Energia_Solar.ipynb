{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **EXERCÍCIOS – Soluções em Energias Renováveis e Sustentáveis**"
      ],
      "metadata": {
        "id": "nb1OcUHAQmxZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objetivos de Aprendizagem**\n",
        "\n",
        "• Diferenciar tarefas de regressão e classificação.\n",
        "\n",
        "• Aplicar ferramentas de análise em Python (pandas, scikit-learn) e no Orange Data Mining.\n",
        "\n",
        "• Compreender como dados de energia podem ser usados para apoiar decisões reais"
      ],
      "metadata": {
        "id": "aHnCoCWPQvvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parte 2 – Classificação (Smart Grid Stability)**"
      ],
      "metadata": {
        "id": "TQahahcvQ2wv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**01) Imports**"
      ],
      "metadata": {
        "id": "CEXVQPxxUrtQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKq7qmBSQflW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**02) Carregar dataset**"
      ],
      "metadata": {
        "id": "kemSUniXVM9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/smart_grid_stability_augmented.csv\")\n",
        "print(\"Dimensões:\", df.shape)\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "bTepUmqYVKfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**03) Verificar colunas e tipos**"
      ],
      "metadata": {
        "id": "KDpecqNoVmJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())"
      ],
      "metadata": {
        "id": "dM-6BBh0Vjdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**04) Definir rótulo**"
      ],
      "metadata": {
        "id": "kBLinDRxV46j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = \"stabf\""
      ],
      "metadata": {
        "id": "wWn1nZp1V0Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificar rótulo (stable/unstable -> 0/1)\n",
        "le = LabelEncoder()\n",
        "df[target_col] = le.fit_transform(df[target_col])\n",
        "\n",
        "# Separar features e target\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]\n",
        "\n",
        "# Escalar features numéricas\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "L2o1SMNEWOqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**05) Divisão treino/teste**"
      ],
      "metadata": {
        "id": "-e5O1op1Wjas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "   X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "Vf80AoO8Wgk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**06) Modelos**"
      ],
      "metadata": {
        "id": "b3pKdsgvXDg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "   \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "   \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "   \"KNN\": KNeighborsClassifier(),\n",
        "   \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "   model.fit(X_train, y_train)\n",
        "   y_pred = model.predict(X_test)\n",
        "\n",
        "   acc = accuracy_score(y_test, y_pred)\n",
        "   f1 = f1_score(y_test, y_pred)\n",
        "   cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "   results[name] = {\"accuracy\": acc, \"f1\": f1, \"cm\": cm}\n",
        "\n",
        "   print(f\"\\n=== {name} ===\")\n",
        "   print(\"Accuracy:\", acc)\n",
        "   print(\"F1:\", f1)\n",
        "   print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "   # Matriz de confusão\n",
        "   sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "   plt.title(f\"Matriz de Confusão - {name}\")\n",
        "   plt.xlabel(\"Predito\")\n",
        "   plt.ylabel(\"Real\")\n",
        "   plt.show()"
      ],
      "metadata": {
        "id": "-498zn5VWvKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**07) Comparar desempenho**"
      ],
      "metadata": {
        "id": "tI-kOtuyYF-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame(results).T\n",
        "print(\"\\nResumo dos Resultados:\")\n",
        "display(df_results)"
      ],
      "metadata": {
        "id": "BUVi7QurYDkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**08) GridSearch para Random Forest**"
      ],
      "metadata": {
        "id": "o9i-GoK4YRhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "   \"n_estimators\": [100, 200],\n",
        "   \"max_depth\": [None, 10, 20],\n",
        "   \"min_samples_leaf\": [1, 2, 4]\n",
        "}\n",
        "grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, scoring=\"f1\", n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nMelhores hiperparâmetros RF:\", grid.best_params_)\n",
        "best_rf = grid.best_estimator_\n",
        "y_pred = best_rf.predict(X_test)\n",
        "print(\"F1 com melhor RF:\", f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "_awuQwTjYO22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusão Comparativa dos Modelos**"
      ],
      "metadata": {
        "id": "JjkiXXn-ciWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os quatro algoritmos de classificação apresentaram desempenhos distintos na tarefa de prever a estabilidade da rede elétrica inteligente:\n",
        "\n",
        "• **Logistic Regression** obteve acurácia de **99,93%** e F1 de **0,999**, errando apenas oito instâncias. Isso mostra que até mesmo um modelo linear consegue separar bem as classes, embora apresente pequenas falhas em identificar todos os casos de instabilidade.\n",
        "\n",
        "• **KNN** apresentou desempenho inferior, com acurácia de **95,26%** e F1 de **0,96**. Esse modelo registrou 568 erros (344 falsos positivos e 224 falsos negativos), revelando maior sensibilidade ao ruído e menor capacidade de generalização em comparação com os demais.\n",
        "\n",
        "• **Decision Tree** alcançou acurácia e F1 perfeitos (**1.0**), classificando todas as amostras corretamente. Apesar disso, por ser um modelo único, está mais sujeito a **overfitting**, pois pode ter memorizado o conjunto de dados em vez de aprender padrões generalizáveis.\n",
        "\n",
        "• **Random Forest** também atingiu resultados perfeitos (**100% de acurácia e F1**), mas com uma vantagem fundamental: como combina várias árvores de decisão, tende a **generalizar melhor**, sendo mais robusto contra overfitting e variações nos dados."
      ],
      "metadata": {
        "id": "wNshdvDdb27e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modelo mais confiável**"
      ],
      "metadata": {
        "id": "UXE3LH4dtuiw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considerando o contexto da aplicação — **detecção de instabilidade em Smart Grids**, onde falsos negativos podem ter consequências graves — o **Random Forest se apresenta como o modelo mais confiável**. Ele alia **desempenho perfeito nos testes** a uma **robustez superior** em relação às demais técnicas, tornando-se a escolha mais indicada para monitoramento e prevenção de falhas em sistemas elétricos inteligentes."
      ],
      "metadata": {
        "id": "__uPiqWTt1gs"
      }
    }
  ]
}